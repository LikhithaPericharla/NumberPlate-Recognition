import requests
import json
import base64
import cv2
from requests.auth import HTTPBasicAuth
from requests_toolbelt.multipart.encoder import MultipartEncoder
filename="car.jpg"

API_ENDPOINT = "https://gateway.watsonplatform.net/visual-recognition/api/v4/analyze?version=2019-02-11"
m = MultipartEncoder(
    fields={"features": "objects","collection_ids":"eeacfa1e-d329-4a1d-a5dc-0d35c4fa049f",
            'images_file':(filename,open(filename,'rb'))}
    )
headers={'Content-Type':m.content_type}

r = requests.post(url=API_ENDPOINT,headers=headers, auth=HTTPBasicAuth("apikey","H7ROt0rd1FNboTHCgbVqyahjYnaTExF7Y9_GoK1odGGD"),data=m)


pastebin_url = r.text
data= json.loads(pastebin_url)
frame=cv2.imread(filename)
frame1=cv2.imread(filename)
print(data)
d=data["images"][0]["objects"]["collections"][0]["objects"]
count=len(d)
cv2.putText(frame, "Count:"+str(count), (350, 30),
cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
for i in d:
    label=i["object"]
    x=i["location"]["left"]
    y=i["location"]["top"]
    w=i["location"]["width"]
    h=i["location"]["height"]
    cv2.putText(frame, label, (x, y),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
    frame = frame[y:y+h, x:x+w]

import numpy
from PIL import Image

filename=Image.fromarray(frame)

import pytesseract

import shutil
import os
import random
text = pytesseract.image_to_string(frame)

print(text)
